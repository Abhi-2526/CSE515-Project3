{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch\n",
    "import scipy\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data download and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Define the transformation for data - \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),   # Resize images to the required size\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert to grayscale if needed\n",
    "    transforms.ToTensor(),           # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "# Load the Caltech 101 dataset\n",
    "caltech101_data100 = torchvision.datasets.Caltech101(\n",
    "    root = './data',                      # Directory where data will be saved\n",
    "    #root='/content/drive/MyDrive',       # If working with the google drive\n",
    "    download=True,                        # Download the dataset if not done\n",
    "    transform=transform                   # Transform the data into required format\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio for each component:\n",
      "[3.83282416e-01 8.85222761e-02 5.59737478e-02 ... 6.87561679e-12\n",
      " 4.17192587e-12 1.15429846e-29]\n",
      "\n",
      "Cumulative Explained Variance:\n",
      "[0.38328242 0.47180469 0.52777844 ... 1.         1.         1.        ]\n",
      "\n",
      "Number of components to explain 95.0% variance: 696\n"
     ]
    }
   ],
   "source": [
    "# Function to load images from the entire Caltech101 dataset\n",
    "def load_caltech101_dataset(dataset_path, target_size=(100, 100)):\n",
    "    images = []\n",
    "\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            image = io.imread(file_path)\n",
    "\n",
    "            # Resize the image to a consistent size\n",
    "            image_resized = resize(image, target_size, anti_aliasing=True)\n",
    "\n",
    "            # Flatten the resized image\n",
    "            flattened_image = image_resized.flatten()\n",
    "\n",
    "            images.append(flattened_image)\n",
    "\n",
    "    # Find the maximum length of flattened images\n",
    "    max_length = max(len(image) for image in images)\n",
    "\n",
    "    # Zero-pad images to ensure a consistent length\n",
    "    padded_images = [np.pad(image, (0, max_length - len(image))) for image in images]\n",
    "\n",
    "    return np.array(padded_images)\n",
    "\n",
    "# Specify the path to the Caltech101 dataset\n",
    "caltech101_path = 'data/caltech101/101_ObjectCategories'\n",
    "\n",
    "# Extract images from the entire dataset\n",
    "caltech101_images = load_caltech101_dataset(caltech101_path)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "caltech101_images_normalized = caltech101_images / 255.0\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca.fit(caltech101_images_normalized)\n",
    "\n",
    "# Print the explained variance ratio for each component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(\"Explained Variance Ratio for each component:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "# Compute and print the cumulative explained variance\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "print(\"\\nCumulative Explained Variance:\")\n",
    "print(cumulative_explained_variance)\n",
    "\n",
    "# Find the number of components that explain a certain threshold of variance (e.g., 95%)\n",
    "threshold_variance = 0.95\n",
    "num_components_threshold = np.argmax(cumulative_explained_variance >= threshold_variance) + 1\n",
    "print(f\"\\nNumber of components to explain {threshold_variance * 100}% variance: {num_components_threshold}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 0B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_caltech101_data(data_dir='./data/caltech101/101_ObjectCategories', target_size=(100, 100)):\n",
    "    image_data = []\n",
    "    labels = []\n",
    "    \n",
    "    for label_index, category in enumerate(os.listdir(data_dir)):\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            for file_name in os.listdir(category_path):\n",
    "                if file_name.startswith('image') and file_name.endswith('.jpg'):\n",
    "                    image_path = os.path.join(category_path, file_name)\n",
    "                    image = cv2.imread(image_path)\n",
    "                    image = cv2.resize(image, target_size)\n",
    "                    image_data.append(image)\n",
    "                    labels.append(label_index)  # Assigning the label index to the image\n",
    "    \n",
    "    return np.array(image_data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "caltech101_data, caltech101_labels = load_caltech101_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: Inherent Dimensionality = 25\n",
      "Label 1: Inherent Dimensionality = 66\n",
      "Label 2: Inherent Dimensionality = 31\n",
      "Label 3: Inherent Dimensionality = 29\n",
      "Label 4: Inherent Dimensionality = 60\n",
      "Label 5: Inherent Dimensionality = 39\n",
      "Label 6: Inherent Dimensionality = 21\n",
      "Label 7: Inherent Dimensionality = 27\n",
      "Label 8: Inherent Dimensionality = 68\n",
      "Label 9: Inherent Dimensionality = 39\n",
      "Label 10: Inherent Dimensionality = 52\n",
      "Label 11: Inherent Dimensionality = 35\n",
      "Label 12: Inherent Dimensionality = 40\n",
      "Label 13: Inherent Dimensionality = 39\n",
      "Label 14: Inherent Dimensionality = 24\n",
      "Label 15: Inherent Dimensionality = 21\n",
      "Label 16: Inherent Dimensionality = 51\n",
      "Label 17: Inherent Dimensionality = 37\n",
      "Label 18: Inherent Dimensionality = 270\n",
      "Label 19: Inherent Dimensionality = 48\n",
      "Label 20: Inherent Dimensionality = 33\n",
      "Label 21: Inherent Dimensionality = 59\n",
      "Label 22: Inherent Dimensionality = 58\n",
      "Label 23: Inherent Dimensionality = 31\n",
      "Label 24: Inherent Dimensionality = 27\n",
      "Label 25: Inherent Dimensionality = 28\n",
      "Label 26: Inherent Dimensionality = 42\n",
      "Label 27: Inherent Dimensionality = 42\n",
      "Label 28: Inherent Dimensionality = 23\n",
      "Label 29: Inherent Dimensionality = 55\n",
      "Label 30: Inherent Dimensionality = 31\n",
      "Label 31: Inherent Dimensionality = 34\n",
      "Label 32: Inherent Dimensionality = 44\n",
      "Label 33: Inherent Dimensionality = 48\n",
      "Label 34: Inherent Dimensionality = 33\n",
      "Label 35: Inherent Dimensionality = 37\n",
      "Label 36: Inherent Dimensionality = 32\n",
      "Label 37: Inherent Dimensionality = 44\n",
      "Label 38: Inherent Dimensionality = 41\n",
      "Label 39: Inherent Dimensionality = 29\n",
      "Label 40: Inherent Dimensionality = 49\n",
      "Label 41: Inherent Dimensionality = 31\n",
      "Label 42: Inherent Dimensionality = 52\n",
      "Label 43: Inherent Dimensionality = 46\n",
      "Label 44: Inherent Dimensionality = 31\n",
      "Label 45: Inherent Dimensionality = 37\n",
      "Label 46: Inherent Dimensionality = 43\n",
      "Label 47: Inherent Dimensionality = 57\n",
      "Label 48: Inherent Dimensionality = 48\n",
      "Label 49: Inherent Dimensionality = 48\n",
      "Label 50: Inherent Dimensionality = 29\n",
      "Label 51: Inherent Dimensionality = 72\n",
      "Label 52: Inherent Dimensionality = 22\n",
      "Label 53: Inherent Dimensionality = 46\n",
      "Label 54: Inherent Dimensionality = 39\n",
      "Label 55: Inherent Dimensionality = 39\n",
      "Label 56: Inherent Dimensionality = 38\n",
      "Label 57: Inherent Dimensionality = 25\n",
      "Label 58: Inherent Dimensionality = 32\n",
      "Label 59: Inherent Dimensionality = 27\n",
      "Label 60: Inherent Dimensionality = 84\n",
      "Label 61: Inherent Dimensionality = 132\n",
      "Label 62: Inherent Dimensionality = 87\n",
      "Label 63: Inherent Dimensionality = 53\n",
      "Label 64: Inherent Dimensionality = 49\n",
      "Label 65: Inherent Dimensionality = 61\n",
      "Label 66: Inherent Dimensionality = 35\n",
      "Label 67: Inherent Dimensionality = 48\n",
      "Label 68: Inherent Dimensionality = 27\n",
      "Label 69: Inherent Dimensionality = 45\n",
      "Label 70: Inherent Dimensionality = 40\n",
      "Label 71: Inherent Dimensionality = 30\n",
      "Label 72: Inherent Dimensionality = 139\n",
      "Label 73: Inherent Dimensionality = 55\n",
      "Label 74: Inherent Dimensionality = 36\n",
      "Label 75: Inherent Dimensionality = 23\n",
      "Label 76: Inherent Dimensionality = 35\n",
      "Label 77: Inherent Dimensionality = 32\n",
      "Label 78: Inherent Dimensionality = 25\n",
      "Label 79: Inherent Dimensionality = 28\n",
      "Label 80: Inherent Dimensionality = 19\n",
      "Label 81: Inherent Dimensionality = 53\n",
      "Label 82: Inherent Dimensionality = 54\n",
      "Label 83: Inherent Dimensionality = 40\n",
      "Label 84: Inherent Dimensionality = 41\n",
      "Label 85: Inherent Dimensionality = 41\n",
      "Label 86: Inherent Dimensionality = 43\n",
      "Label 87: Inherent Dimensionality = 40\n",
      "Label 88: Inherent Dimensionality = 350\n",
      "Label 89: Inherent Dimensionality = 40\n",
      "Label 90: Inherent Dimensionality = 46\n",
      "Label 91: Inherent Dimensionality = 255\n",
      "Label 92: Inherent Dimensionality = 51\n",
      "Label 93: Inherent Dimensionality = 23\n",
      "Label 94: Inherent Dimensionality = 45\n",
      "Label 95: Inherent Dimensionality = 214\n",
      "Label 96: Inherent Dimensionality = 229\n",
      "Label 97: Inherent Dimensionality = 58\n",
      "Label 98: Inherent Dimensionality = 56\n",
      "Label 99: Inherent Dimensionality = 47\n",
      "Label 100: Inherent Dimensionality = 36\n",
      "Label 101: Inherent Dimensionality = 18\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def compute_inherent_dimensionality(images, n_components=0.95):\n",
    "    # Flatten the images\n",
    "    flattened_images = images.reshape(images.shape[0], -1)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(flattened_images)\n",
    "\n",
    "    # Get the number of principal components\n",
    "    num_components = pca.n_components_\n",
    "\n",
    "    return num_components\n",
    "\n",
    "# Iterate over unique labels and calculate inherent dimensionality\n",
    "unique_labels = np.unique(caltech101_labels)\n",
    "for label in unique_labels:\n",
    "    label_indices = np.where(caltech101_labels == label)[0]\n",
    "    label_images = caltech101_data[label_indices]\n",
    "\n",
    "    inherent_dimensionality = compute_inherent_dimensionality(label_images)\n",
    "    print(f\"Label {label}: Inherent Dimensionality = {inherent_dimensionality}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
