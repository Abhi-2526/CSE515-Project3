{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import torch \n",
    "from torchvision import transforms, models \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import LatentDirichletAllocation \n",
    "from scipy.spatial import distance\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "131740031it [00:04, 26916279.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/niteeqsheik/Desktop/Phase3/caltech101/101_ObjectCategories.tar.gz to /Users/niteeqsheik/Desktop/Phase3/caltech101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14028800it [00:00, 18831818.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/niteeqsheik/Desktop/Phase3/caltech101/Annotations.tar to /Users/niteeqsheik/Desktop/Phase3/caltech101\n",
      "8677\n"
     ]
    }
   ],
   "source": [
    "dataset = torchvision.datasets.Caltech101('/Users/niteeqsheik/Desktop/Phase3',download=True)\n",
    "data_loader = torch.utils.data.DataLoader(dataset,\n",
    "batch_size=4,\n",
    "shuffle=True,\n",
    "num_workers=8)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4339\n"
     ]
    }
   ],
   "source": [
    "even_indices = [i for i in range(0, len(dataset), 2)]\n",
    "even_dataset = Subset(dataset, even_indices)\n",
    "even_data_loader = torch.utils.data.DataLoader(even_dataset, batch_size=4, shuffle=True, num_workers=8)\n",
    "print(len(even_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 4339/4339 [02:53<00:00, 25.08it/s]\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),             # Resize the image to 256x256 pixels\n",
    "    transforms.CenterCrop(224),         # Crop the image to 224x224 pixels about the center\n",
    "    transforms.Grayscale(num_output_channels=3),  \n",
    "    transforms.ToTensor(),              # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.53994344, 0.52009986, 0.49254049], std=[0.31415099, 0.30712622, 0.31878401]),  # Normalize the image\n",
    "])\n",
    "def extract_features_individual(even_dataset, model, transform):\n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for image, label in tqdm(even_dataset, desc=\"Extracting Features\"):\n",
    "            image = transform(image).unsqueeze(0)  # Apply transform and add batch dimension\n",
    "            output = model(image)\n",
    "            features.append(output.squeeze(0)) \n",
    "            labels.append(label) # Remove batch dimension\n",
    "    return features,labels\n",
    "# Extract Features from Even-Numbered Images\n",
    "even_features, even_labels = extract_features_individual(even_dataset, resnet50, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from torchvision import datasets, transforms\n",
    "# from torch.utils.data import Subset\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming you have already defined and loaded your dataset and even_dataset\n",
    "\n",
    "# # Function to show an image\n",
    "# def imshow(img):\n",
    "#     img = img / 2 + 0.5  # unnormalize\n",
    "#     npimg = img.numpy()\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "#     plt.show()\n",
    "\n",
    "# # Display three images for each label\n",
    "# unique_labels = set(even_labels)\n",
    "\n",
    "# for label in unique_labels:\n",
    "#     print(f\"Label: {label}\")\n",
    "#     count = 0\n",
    "#     for i, (image, lbl) in enumerate(even_dataset):\n",
    "#         if lbl == label and count < 3:\n",
    "#             imshow(transforms.ToTensor()(image))\n",
    "#             count += 1\n",
    "#         if count >= 3:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier for even numbered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np \n",
    "def prepare_knn_classifier(k,features,labels):\n",
    "    \"\"\"\n",
    "    Prepares a k-NN classifier.\n",
    "\n",
    "    Args:\n",
    "    k (int): The number of neighbors to use for k-NN.\n",
    "    features (list of torch.Tensor): The list of feature tensors from the ResNet model.\n",
    "    labels (list): The list of labels corresponding to the features.\n",
    "\n",
    "    Returns:\n",
    "    KNeighborsClassifier: The trained k-NN classifier\n",
    "    \"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors = k) \n",
    "    knn.fit(features,labels)\n",
    "    return knn \n",
    "db_path = 'caltech101_features.db'\n",
    "even_features_db,even_labels_db = utils.load_even_images_and_labels(db_path)\n",
    "\n",
    "#convert the list of numpy arrays to 2D numpy arrays \n",
    "X = np.stack(even_features_db)\n",
    "y = np.array(even_labels_db)\n",
    "k = int(input(\"Enter the number of neighbors for k-NN: \"))\n",
    "knn_classifier = prepare_knn_classifier(k,X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(features, labels, **dt_params): \n",
    "    \"\"\"\n",
    "    Trains a Decision Tree classifier using all provided features and labels.\n",
    "\n",
    "    Args:\n",
    "    features (numpy.ndarray): The feature vectors.\n",
    "    labels (numpy.ndarray): The labels corresponding to the features.\n",
    "    **dt_params: Additional parameters to pass to the Decision Tree classifier.\n",
    "\n",
    "    Returns:\n",
    "    DecisionTreeClassifier: The trained Decision Tree classifier.\n",
    "    \"\"\"\n",
    "    # Initialize the Decision Tree classifier\n",
    "    decision_tree = DecisionTreeClassifier(**dt_params)\n",
    "\n",
    "    # Train the classifier\n",
    "    decision_tree.fit(features, labels)\n",
    "\n",
    "    return decision_tree\n",
    "decision_tree_classifier = train_decision_tree(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4339,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "features_array = np.stack(even_labels_db)\n",
    "print(features_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The elements of even_features are NumPy arrays.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check if even_features is a list of NumPy arrays\n",
    "if len(even_features_db) > 0 and isinstance(even_features_db[0], np.ndarray):\n",
    "    print(\"The elements of even_features are NumPy arrays.\")\n",
    "else:\n",
    "    print(\"The elements of even_features are not NumPy arrays.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/niteeqsheik/Desktop/Phase3/Task3.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niteeqsheik/Desktop/Phase3/Task3.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niteeqsheik/Desktop/Phase3/Task3.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Ensure all tensors are on the CPU and convert to NumPy arrays\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/niteeqsheik/Desktop/Phase3/Task3.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m even_features_np \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack([tensor\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy() \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m even_features_db])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niteeqsheik/Desktop/Phase3/Task3.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCombined features shape:\u001b[39m\u001b[39m\"\u001b[39m, even_features_np\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;32m/Users/niteeqsheik/Desktop/Phase3/Task3.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niteeqsheik/Desktop/Phase3/Task3.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niteeqsheik/Desktop/Phase3/Task3.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Ensure all tensors are on the CPU and convert to NumPy arrays\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/niteeqsheik/Desktop/Phase3/Task3.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m even_features_np \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack([tensor\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy() \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m even_features_db])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niteeqsheik/Desktop/Phase3/Task3.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCombined features shape:\u001b[39m\u001b[39m\"\u001b[39m, even_features_np\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Ensure all tensors are on the CPU and convert to NumPy arrays\n",
    "# even_features_np = np.stack([tensor.cpu().numpy() for tensor in even_features_db])\n",
    "\n",
    "# print(\"Combined features shape:\", even_features_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: PageRank failed to converge for label '14' at node 0. (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 500 iterations')\n",
      "Error: PageRank failed to converge for label '92' at node 0. (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 500 iterations')\n",
      "Error: PageRank failed to converge for label '95' at node 0. (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 500 iterations')\n",
      "Error: PageRank failed to converge for label '86' at node 0. (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 500 iterations')\n",
      "Error: PageRank failed to converge for label '15' at node 0. (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 500 iterations')\n",
      "Error: PageRank failed to converge for label '23' at node 0. (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 500 iterations')\n",
      "Error: PageRank failed to converge for label '68' at node 0. (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 500 iterations')\n",
      "Error: PageRank failed to converge for label '82' at node 0. (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 500 iterations')\n",
      "Error: PageRank failed to converge for label '26' at node 0. (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 500 iterations')\n",
      "Error: PageRank failed to converge for label '100' at node 0. (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 500 iterations')\n",
      "Error: PageRank failed to converge for label '1' at node 0. (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 500 iterations')\n",
      "Error: PageRank failed to converge for label '85' at node 0. (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 500 iterations')\n",
      "Error: PageRank failed to converge for label '78' at node 0. (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 500 iterations')\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def create_similarity_graph(features):\n",
    "    \"\"\"\n",
    "    Creates an undirected graph based on cosine similarity between features.\n",
    "\n",
    "    Args:\n",
    "    features (numpy.ndarray): Feature vectors of the images.\n",
    "\n",
    "    Returns:\n",
    "    networkx.Graph: An undirected graph representing the similarities between images.\n",
    "    \"\"\"\n",
    "    similarity_matrix = cosine_similarity(features)\n",
    "    G = nx.Graph()\n",
    "    for i in range(similarity_matrix.shape[0]):\n",
    "        for j in range(similarity_matrix.shape[1]):\n",
    "            if i != j:  # Avoid self-loops\n",
    "                G.add_edge(i, j, weight=similarity_matrix[i][j])\n",
    "    return G\n",
    "\n",
    "def personalized_pagerank_classifier(graph, labels, alpha=0.85, max_iter=500):\n",
    "    unique_labels = set(labels)\n",
    "    predictions = {}\n",
    "\n",
    "    for node in graph.nodes():\n",
    "        pagerank_scores = {}\n",
    "        for label in unique_labels:\n",
    "            personalization = {i: 0.1 if labels[i] != label else 1 for i in graph.nodes()}  # Softer personalization\n",
    "            try:\n",
    "                pagerank = nx.pagerank(graph, alpha=alpha, personalization=personalization, max_iter=max_iter)\n",
    "                pagerank_scores[label] = pagerank[node]\n",
    "                print(f\"Success: PageRank converged for label '{label}' at node {node}.\")\n",
    "            except nx.PowerIterationFailedConvergence as e:\n",
    "                print(f\"Error: PageRank failed to converge for label '{label}' at node {node}. {e}\")\n",
    "                pagerank_scores[label] = 0  # Handle non-convergence\n",
    "\n",
    "        predicted_label = max(pagerank_scores, key=pagerank_scores.get)\n",
    "        predictions[node] = predicted_label\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Load your features and labels\n",
    "# even_features, even_labels = ...\n",
    "\n",
    "# Create a graph based on the features\n",
    "G = create_similarity_graph(np.stack(even_features_db))\n",
    "\n",
    "# Classify the images\n",
    "predictions = personalized_pagerank_classifier(G, even_labels_db)\n",
    "\n",
    "# Now, `predictions` contains the predicted labels for each image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WebDB_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
